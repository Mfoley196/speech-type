---
title: "TLX Stats"
author: ""
date: "August 13, 2019"
output: 
   html_document: 
     dev: png
     fig_height: 5
     fig_width: 5.5
     number_sections: yes
     toc: yes
     toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ARTool)
library(reshape2)
library(ez)
library(apa)
library(gridExtra)
library(phia)
library(viridis)
library(lsmeans)
library(gmodels)
library(DescTools)
library(MASS)
library(pander)
library(reticulate)
library(ggpubr)
library(xtable)
# Needed to correctly export fonts in pdf (may not be required)
library(extrafont)
# Need to call extrafont::font_import() once in console and restart RStudio
library(emmeans)
```


```{r functions, echo=FALSE}

normalCheck = function(model) {
    res = residuals(model)
    qqnorm((res - mean(res)) / sd(res))
    abline(0, 1)
    print (shapiro.test(res))
}
```

```{python usefulfunctions, echo=FALSE}
import re
def parseAnova(s):
  aovres = re.findall(r'[-+]?\d*\.\d+|\d+',s)
  return "\\anova{%s}{%s}{%s}{%s}{%s}"%(aovres[0], aovres[1], aovres[2], aovres[3], aovres[4])
  
def writeToFile(s, file):
  f = open("autogen/" + file,"w+")
  f.write("% do not edit this file as it was automatically generated\n\n")
  f.write(s)
  f.close()
```

# Data Parsing

## Loading Data

Filtering out invalid participants (9, 10, and 14).

```{r load}
survey = read.csv("Mobile Input Experiment Survey Responses.csv",sep=",")
survey = survey[,-c(1,2)] %>% filter(!pNo %in% c(9, 10, 14))

tlx.comp = read.csv("NASA-TLX Responses - Comp.csv",sep=",") %>% filter(!Participant.No %in% c(9, 10, 14)) %>% na.omit()
tlx.comp$Task.Type = "Composition"

tlx.trans = read.csv("NASA-TLX Responses - Trans.csv",sep=",") %>% filter(!Participant.No %in% c(9, 10, 14)) %>% na.omit()
tlx.trans$Task.Type = "Transcription"

tlx = bind_rows(tlx.comp, tlx.trans)
```

# Demographic Survey

```{r survey, eval=TRUE, include=TRUE}

kable(count(survey, Gender))

#Age stats
ageRange = range(survey$Age)
ageRange[2]
median(survey$Age)
sd(survey$Age)

#Phone Stats
kable(count(survey, PhoneOS))

#TODO: do something with the usage stats

#Dictation Stats
kable(count(survey, UsedDict))

#Filter participants into dictation users and non-dictation users
survey.DictUsers = filter(survey, UsedDict == "Yes")
survey.NonUsers = filter(survey, UsedDict == "No")

kable(count(survey.DictUsers, DictFreq))

kable(count(survey.DictUsers, OwnAlexa))
kable(count(survey.DictUsers, AlexaFreq))

kable(count(survey.NonUsers, OwnAlexa2))
```


28 participants, 11 female, 17 male.

Partcipants ranged in age from `r ageRange[1]` to `r ageRange[2]`, M = 25, SD = 7.163

All participants owned a smartphone. 17 used Android, 10 used iOS.

10 participants reported that they had never used dictation. Of the 17 participants who reported that they had used dictation, 8 said they had only tried it once or twice, and 5 reported monthly dictation use. 4 of these 17 participants reported using dictation either daily, or weekly.

10 of the dictation users owned a Google Home, Alexa, or a similar device. Of these 10, 9 reported they used their device on a daily or weekly basis. Only 1 of the participants who did not use dictation owned a smart assistant.

# NASA-TLX Results

## Composition

The only difference that looks big here is that participants found speech much less physically demanding. Speech was slightly more mentally demanding and frustrating, and participants felt their performance was slightly better with Keyboard.

```{r tlx-comp, warning=FALSE}
#tlx.melt = melt(tlx.comp, id.vars = c("Input.Type", "Participant.No", "Task.Type")) %>% group_by(variable, Input.Type) %>% summarise(mean=mean(value),ci.upper=ci(value)[3], ci.lower=ci(value)[2])
tlx.melt = melt(tlx.comp, id.vars = c("Input.Type", "Participant.No", "Task.Type"))
```

```{r compgraph, warning=FALSE, message=FALSE}
tlx_g <- ggplot(tlx.melt, aes(x=variable, y=value, fill=Input.Type)) + geom_boxplot(width=.4) +
   theme(axis.text.x=element_text(angle=25, hjust=1)) +
   scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
   scale_y_continuous(name="Composition", limits = c(0, 110), minor_breaks = 25, expand = c(0, 0)) +
   scale_x_discrete(name="", labels=c("Mental Demand", "Physical Demand", "Temporal Demand", "Performance", "Effort", "Frustration")) +
   labs(fill = "Input") +
   coord_flip() +
   theme(legend.position = c(.9, .85),
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        axis.text = element_text(family="Helvetica", colour="black", size="14"),
        panel.grid.major.y = element_line( size = .1, color = "grey"),
        legend.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        legend.text = element_text(family="Helvetica", face="bold", colour="black", size="14"))
tlx_g
```

## Transcription

All measures favour Speech here by a long shot.

```{r tlx-trans, warning=FALSE}
#tlx.melt.tr = melt(tlx.trans, id.vars = c("Input.Type", "Participant.No", "Task.Type")) %>% group_by(variable, Input.Type) %>% summarise(mean=mean(value),ci.upper=ci(value)[3], ci.lower=ci(value)[2])
tlx.melt.tr = melt(tlx.trans, id.vars = c("Input.Type", "Participant.No", "Task.Type"))
```

```{r transgraph, warning=FALSE, message=FALSE}
tlx_t_g <- ggplot(tlx.melt.tr, aes(x=variable, y=value, fill=Input.Type)) + geom_boxplot(width=.4) +
   #geom_errorbar(aes(ymin = ci.lower, ymax = ci.upper), width = 0.1, size = 0.7, position=position_dodge(.9)) +
   theme(axis.text.x=element_text(angle=25, hjust=1)) +
   scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
   scale_y_continuous(name="Transcription", limits = c(0, 110), minor_breaks = 25, expand = c(0, 0)) +
   scale_x_discrete(name="", labels=c("Mental Demand", "Physical Demand", "Temporal Demand", "Performance", "Effort", "Frustration")) +
   labs(fill = "Input") +
   coord_flip() +
   theme(legend.position = c(.9, .85),
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.line.y = element_blank(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        axis.text = element_text(family="Helvetica", colour="black", size="14"),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        panel.grid.major.y = element_line( size = .1, color = "grey"),
        legend.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        legend.text = element_text(family="Helvetica", face="bold", colour="black", size="14"))
tlx_t_g
```

```{r warning=FALSE, message=FALSE}
ggarrange(tlx_g, tlx_t_g ,
          nrow = 1, ncol = 2,
          widths = c(1.5,1),
          common.legend = TRUE, legend = "bottom")

ggsave("figures/tlx.pdf",
       height = 5 , width = 7,
       plot = last_plot(), # or give ggplot object name as in myPlot,
       dpi = 300)
```

## Significance Testing

Aggregating data for further analysis

```{r}
tlx.comp.group = group_by(tlx.comp, Task.Type, Input.Type) %>%
  summarize(md = mean(Mental.Demand),
            pd = mean(Physical.Demand),
            td = mean(Temporal.Demand),
            p = mean(Performance),
            e = mean(Effort),
            f = mean(Frustration))

perf.stats.c = group_by(tlx.comp, Task.Type) %>%
  summarize(p = mean(Performance))

tlx.trans.group = group_by(tlx.trans, Task.Type, Input.Type) %>%
  summarize(md = mean(Mental.Demand),
            pd = mean(Physical.Demand),
            td = mean(Temporal.Demand),
            p = mean(Performance),
            e = mean(Effort),
            f = mean(Frustration))

tlx.comp.group.md = group_by(tlx.comp, Task.Type, Input.Type) %>%
  summarize(md = median(Mental.Demand),
            pd = median(Physical.Demand),
            td = median(Temporal.Demand),
            p = median(Performance),
            e = median(Effort),
            f = median(Frustration))

tlx.trans.group.md = group_by(tlx.trans, Task.Type, Input.Type) %>%
  summarize(md = median(Mental.Demand),
            pd = median(Physical.Demand),
            td = median(Temporal.Demand),
            p = median(Performance),
            e = median(Effort),
            f = median(Frustration))

perf.stats.t = group_by(tlx.trans, Task.Type) %>%
  summarize(p = mean(Performance))

tlx.group = bind_rows(tlx.comp.group, tlx.trans.group)
tlx.group.md = bind_rows(tlx.comp.group.md, tlx.trans.group.md)

#perf.stats = bind_rows(perf.stats.c, perf.stats.t)
perf.stats = group_by(tlx, Task.Type) %>%
  summarize(td = mean(Performance))

td.stats = group_by(tlx, Input.Type) %>%
  summarize(td = mean(Temporal.Demand))

tlx.long = melt(tlx, id.vars= c("Participant.No", "Input.Type", "Mental.Demand", "Physical.Demand", "Temporal.Demand", "Effort", "Frustration", "Performance", "Task.Type"))
tlx.long$Input.Type = factor(tlx.long$Input.Type)
tlx.long$Task.Type = factor(tlx.long$Task.Type)
tlx.long$Participant.No = factor(tlx.long$Participant.No)

kable(tlx.group)
kable(tlx.group.md)
```

### Mental Demand


```{r warning=FALSE, message=FALSE}
a <- tlx %>% unite("input_task", c("Input.Type", "Task.Type"))
b <- dplyr::select(a, Participant.No, input_task, Mental.Demand)
mdata = melt(b, id=c("Participant.No","input_task","Mental.Demand"))

data_tr = mdata %>% spread(input_task, Mental.Demand)
data_tr$Participant.No = NULL
data_tr$variable = NULL
data_tr$value = NULL

res = friedman.test(data.matrix(data_tr))
pander(res)

res = pairwise.wilcox.test(mdata$Mental.Demand, mdata$input_task, paired = TRUE, p.adj = "bonf")
kable(res$p.value)

kable(aggregate(Mental.Demand~input_task, mdata, median))
```



```{r}
#tlx_md <- filter(tlx)
# m <- aov(Mental.Demand ~ Task.Type*Input.Type, data=tlx.long)
# pander(normalCheck(m))
# 
# a = art(Mental.Demand ~ Task.Type*Input.Type + (1|Participant.No), data=tlx.long)
# anova(a)


# boxcox(Mental.Demand ~ Task.Type*Input.Type, data=tlx.long, plotit=T)
# 
# tlxtr = tlx.long %>%
#     mutate(Mental.Demand = Mental.Demand^(0.45))
# 
# m <- aov(Mental.Demand ~ Task.Type*Input.Type, data=tlxtr)
# pander(normalCheck(m))

```

#### Post-hoc comparisons with pairwise comparisons 

```{r warning=FALSE}
# ck_vs_tk = wilcox.test(tlx.long[tlx.long$Task.Type == "Composition" & tlx.long$Input.Type == "Keyboard",]$Mental.Demand, 
#                        tlx.long[tlx.long$Task.Type == "Transcription" & tlx.long$Input.Type == "Keyboard",]$Mental.Demand)$p.value
# ck_vs_cs = wilcox.test(tlx.long[tlx.long$Task.Type == "Composition" & tlx.long$Input.Type == "Keyboard",]$Mental.Demand, 
#                        tlx.long[tlx.long$Task.Type == "Composition" & tlx.long$Input.Type == "Speech",]$Mental.Demand)$p.value
# tk_vs_ts = wilcox.test(tlx.long[tlx.long$Task.Type == "Transcription" & tlx.long$Input.Type == "Keyboard",]$Mental.Demand, 
#                        tlx.long[tlx.long$Task.Type == "Transcription" & tlx.long$Input.Type == "Speech",]$Mental.Demand)$p.value
# cs_vs_ts = wilcox.test(tlx.long[tlx.long$Task.Type == "Composition" & tlx.long$Input.Type == "Speech",]$Mental.Demand, 
#                        tlx.long[tlx.long$Task.Type == "Transcription" & tlx.long$Input.Type == "Speech",]$Mental.Demand)$p.value
# 
# p = p.adjust(c(ck_vs_tk, ck_vs_cs, tk_vs_ts, cs_vs_ts), method="holm")
# format(p, scientific=FALSE)
```


### Physical Demand

```{r warning=FALSE, message=FALSE}
a <- tlx %>% unite("input_task", c("Input.Type", "Task.Type"))
b <- dplyr::select(a, Participant.No, input_task, Physical.Demand)
mdata = melt(b, id=c("Participant.No","input_task","Physical.Demand"))

data_tr = mdata %>% spread(input_task, Physical.Demand)
data_tr$Participant.No = NULL
data_tr$variable = NULL
data_tr$value = NULL

res = friedman.test(data.matrix(data_tr))
pander(res)

res = pairwise.wilcox.test(mdata$Physical.Demand, mdata$input_task, paired = TRUE, p.adj = "bonf")
kable(res$p.value)

kable(aggregate(Physical.Demand~input_task, mdata, median))
```

<!-- The data is not normally distributed. Used the Aligned Rank Transform to run an ANOVA. -->

```{r}
# m <- aov(Physical.Demand ~ Task.Type*Input.Type, data=tlx.long)
# pander(normalCheck(m))
# 
# a = art(Physical.Demand ~ Task.Type*Input.Type + (1|Participant.No), data=tlx.long)
# anova(a)

```

<!-- There is a significant difference between keyboard and speech (not that that's overly surprising) -->

### Temporal Demand

```{r warning=FALSE, message=FALSE}
a <- tlx %>% unite("input_task", c("Input.Type", "Task.Type"))
b <- dplyr::select(a, Participant.No, input_task, Temporal.Demand)
mdata = melt(b, id=c("Participant.No","input_task","Temporal.Demand"))

data_tr = mdata %>% spread(input_task, Temporal.Demand)
data_tr$Participant.No = NULL
data_tr$variable = NULL
data_tr$value = NULL

res = friedman.test(data.matrix(data_tr))
pander(res)

res = pairwise.wilcox.test(mdata$Temporal.Demand, mdata$input_task, paired = TRUE, p.adj = "bonf")
kable(res$p.value)

kable(aggregate(Temporal.Demand~input_task, mdata, median))
```

<!-- The data is not normally distributed...? Will use the Aligned Rank Transform to run an ANOVA. -->

<!-- ```{r} -->
<!-- m <- aov(Temporal.Demand ~ Task.Type*Input.Type, data=tlx.long) -->
<!-- pander(normalCheck(m)) -->

<!-- a = art(Temporal.Demand ~ Task.Type*Input.Type + (1|Participant.No), data=tlx.long) -->
<!-- anova(a) -->

<!-- ``` -->

<!-- There is a significant difference between keyboard and speech. -->

### Performance

```{r warning=FALSE, message=FALSE}
a <- tlx %>% unite("input_task", c("Input.Type", "Task.Type"))
b <- dplyr::select(a, Participant.No, input_task, Performance)
mdata = melt(b, id=c("Participant.No","input_task","Performance"))

data_tr = mdata %>% spread(input_task, Performance)
data_tr$Participant.No = NULL
data_tr$variable = NULL
data_tr$value = NULL

res = friedman.test(data.matrix(data_tr))
pander(res)

res = pairwise.wilcox.test(mdata$Performance, mdata$input_task, paired = TRUE, p.adj = "bonf")
kable(res$p.value)

kable(aggregate(Performance~input_task, mdata, median))
```

<!-- The data is not normally distributed. Will use the Aligned Rank Transform to run an ANOVA. -->

<!-- ```{r} -->
<!-- m <- aov(Performance ~ Task.Type*Input.Type, data=tlx.long) -->
<!-- pander(normalCheck(m)) -->

<!-- m = art(Performance ~ Task.Type*Input.Type + (1|Participant.No), data=tlx.long) -->
<!-- anova(m) -->
<!-- ``` -->

<!-- There is a significant difference between tasks (p < 0.05). -->

### Effort

```{r warning=FALSE, message=FALSE}
a <- tlx %>% unite("input_task", c("Input.Type", "Task.Type"))
b <- dplyr::select(a, Participant.No, input_task, Effort)
mdata = melt(b, id=c("Participant.No","input_task","Effort"))

data_tr = mdata %>% spread(input_task, Effort)
data_tr$Participant.No = NULL
data_tr$variable = NULL
data_tr$value = NULL

res = friedman.test(data.matrix(data_tr))
pander(res)

res = pairwise.wilcox.test(mdata$Effort, mdata$input_task, paired = TRUE, p.adj = "bonf")
kable(res$p.value)

kable(aggregate(Effort~input_task, mdata, median))
```

<!-- The data is normally distributed. A repeated measures ANOVA will be run. -->

<!-- ```{r} -->
<!-- m <- aov(Effort ~ Task.Type*Input.Type, data=tlx.long) -->
<!-- pander(normalCheck(m)) -->

<!-- anova <- ezANOVA(tlx.long, dv=.(Effort), wid=.(Participant.No), within=.(Task.Type, Input.Type), detailed=TRUE) -->
<!-- anova -->

<!-- kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE)) -->
<!-- ``` -->

<!-- There are significant differences between input types (p < 0.05), and task types (p < 0.01), and the interaction between the two (p < 0.001). -->

<!-- #### Post-hoc comparisons with TukeyHSD -->
<!-- ```{r} -->
<!-- t <- TukeyHSD(m) -->
<!-- kable(t$`Task.Type:Input.Type`) -->
<!-- ``` -->

<!-- Transcription:Speech vs Composition:Keyboard, Transcription:Speech vs Transcription:Keyboard, and Transcription:Speech vs Composition:Speech are all significant. -->

### Frustration

```{r warning=FALSE, message=FALSE}
a <- tlx %>% unite("input_task", c("Input.Type", "Task.Type"))
b <- dplyr::select(a, Participant.No, input_task, Frustration)
mdata = melt(b, id=c("Participant.No","input_task","Frustration"))

data_tr = mdata %>% spread(input_task, Frustration)
data_tr$Participant.No = NULL
data_tr$variable = NULL
data_tr$value = NULL

res = friedman.test(data.matrix(data_tr))
pander(res)

res = pairwise.wilcox.test(mdata$Frustration, mdata$input_task, paired = TRUE, p.adj = "bonf")
kable(res$p.value)

kable(aggregate(Frustration~input_task, mdata, median))
```

<!-- The data is not normally distributed. Will use the Aligned Rank Transform to run an ANOVA. -->

<!-- ```{r} -->
<!-- m <- aov(Frustration ~ Task.Type*Input.Type, data=tlx.long) -->
<!-- pander(normalCheck(m)) -->

<!-- a = art(Frustration ~ Task.Type*Input.Type + (1|Participant.No), data=tlx.long) -->
<!-- anova(a) -->
<!-- ``` -->

<!-- Significant interaction between task type and input type. -->

<!-- #### Post-hoc comparisons with pairwise comparisons  -->

<!-- ```{r warning=FALSE} -->
<!-- ck_vs_tk = wilcox.test(tlx.long[tlx.long$Task.Type == "Composition" & tlx.long$Input.Type == "Keyboard",]$Frustration,  -->
<!--                        tlx.long[tlx.long$Task.Type == "Transcription" & tlx.long$Input.Type == "Keyboard",]$Frustration)$p.value -->
<!-- ck_vs_cs = wilcox.test(tlx.long[tlx.long$Task.Type == "Composition" & tlx.long$Input.Type == "Keyboard",]$Frustration,  -->
<!--                        tlx.long[tlx.long$Task.Type == "Composition" & tlx.long$Input.Type == "Speech",]$Frustration)$p.value -->
<!-- tk_vs_ts = wilcox.test(tlx.long[tlx.long$Task.Type == "Transcription" & tlx.long$Input.Type == "Keyboard",]$Frustration,  -->
<!--                        tlx.long[tlx.long$Task.Type == "Transcription" & tlx.long$Input.Type == "Speech",]$Frustration)$p.value -->
<!-- cs_vs_ts = wilcox.test(tlx.long[tlx.long$Task.Type == "Composition" & tlx.long$Input.Type == "Speech",]$Frustration,  -->
<!--                        tlx.long[tlx.long$Task.Type == "Transcription" & tlx.long$Input.Type == "Speech",]$Frustration)$p.value -->

<!-- p = p.adjust(c(ck_vs_tk, ck_vs_cs, tk_vs_ts, cs_vs_ts), method="holm") -->
<!-- format(p, scientific=FALSE) -->

<!-- ``` -->

<!-- When using Tukey HSD on the untransformed data, there is a significant difference between Transcription:Speech vs. Transcription:Keyboard (p < 0.05). -->