---
title: "Speech Input Stats"
author: ""
date: "June 27, 2019"
output: 
   html_document: 
     dev: png
     fig_height: 5
     fig_width: 5.5
     number_sections: yes
     toc: yes
     toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ARTool)
library(reshape2)
library(ez)
library(apa)
library(gridExtra)
library(phia)
library(viridis)
library(lsmeans)
library(gmodels)
library(DescTools)
library(MASS)
library(pander)
library(reticulate)
library(ggpubr)
library(xtable)
library(emmeans)
# Needed to correctly export fonts in pdf (may not be required)
library(extrafont)
# Need to call extrafont::font_import() once in console and restart RStudio
```

```{r functions, echo=FALSE, warning=FALSE}

normalCheck = function(model) {
    res = residuals(model)
    qqnorm((res - mean(res)) / sd(res))
    abline(0, 1)
    print (shapiro.test(res))
}

createPlot = function(data, mean_var, cl_var, cu_var, vj, lx, ly, y_axis, lim_min = 0, lim_max = 33, breaks = 5, x_var = "taskType", angle = 0) {
  localenv <- environment()
  if (is.element(mean_var, c("mIT", "mTT", "mET", "mPT", "mCT"))) {
    data[mean_var] = data[mean_var] / 1000
    data[cl_var] = data[cl_var] / 1000
    data[cu_var] = data[cu_var] / 1000
  } 
  
  if (mean_var=="m_cer" | mean_var=="m_uer") {
    data[mean_var] = data[mean_var] * 100
    data[cl_var] = data[cl_var] * 100
    data[cu_var] = data[cu_var] * 100
  }
  
  ggplot(data, aes(x=data[[x_var]], y=data[[mean_var]], fill=inputType), environment = localenv ) +
  geom_bar(aes(group=inputType), position = position_dodge(.7), colour="black", stat="identity", width=.7) +
  geom_errorbar(aes(ymin = data[[cl_var]], ymax = data[[cu_var]]), width = 0.2, size = .7, position = position_dodge(.7)) +
  geom_text(aes(label=round(data[[mean_var]],digits=2)), size = 4, position = position_dodge(0.7), vjust = vj, alignment="center") +
  scale_x_discrete(name="Task") +
  scale_y_continuous(name=y_axis, limits = c(lim_min, lim_max), minor_breaks = breaks, expand = c(0, 0)) +
  #scale_fill_viridis(option="inferno", begin=0.5, end = .8, discrete = TRUE) +
  #scale_fill_viridis(option="magma", begin=0.5, end = .8, discrete = TRUE) +
  scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
  labs(fill = "Input Type") +
  theme(legend.position = c(lx, ly),
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="10"),
        axis.text = element_text(family="Helvetica", colour="black", size="10"),
        axis.text.x=element_text(angle=angle, hjust=1),
        panel.grid.major.y = element_line( size = .1, color = "grey"))
}
```

```{python usefulfunctions, echo=FALSE}
import re
def parseAnova(s):
  aovres = re.findall(r'[-+]?\d*\.\d+|\d+',s)
  return "\\anova{%s}{%s}{%s}{%s}{%s}"%(aovres[0], aovres[1], aovres[2], aovres[3], aovres[4])
  
def writeToFile(s, file):
  f = open("autogen/" + file,"w+")
  f.write("% do not edit this file as it was automatically generated\n\n")
  f.write(s)
  f.close()
```

# Data Parsing

## Loading Data

Filtering out invalid participants (9, 10, and 14).

```{r load}
data_c = read.csv("parse_more.csv",sep=",") %>% filter(!participantNo %in% c(9, 10, 14))
data_c = data_c[,!names(data_c) %in% c("incorrect_fixed", "fixes", "correct", "inf", "correctMsg", "gMsg")]
data_c$totalTime = data_c$inputTime + data_c$prepTime
data_c.kbd = filter(data_c, inputType=="Keyboard")
data_c.sr = filter(data_c, inputType=="Speech")

data_t = read.csv("parse_more_trans.csv",sep=",")
data_t = data_t[,!names(data_t) %in% c("incorrect_fixed", "fixes", "correct", "inf", "msg", "orgMsg")]
data_t$totalTime = data_t$inputTime + data_t$prepTime
data_t$setNum = substr(data_t$setNum, 1, 1)
data_t.kbd = filter(data_t, inputType=="Keyboard")
data_t.sr = filter(data_t, inputType=="Speech")

```

## Outlier Culling

I removed values outside of 3 standard deviations for the means of each task x method combination, for totalTime.

22 outliers identified for composition (2.04% of trials)

```{r outliers_comp, warning=FALSE, message=FALSE, echo=FALSE}
dcs = summarize(group_by(data_c, inputType), mIT = mean(inputTime), sdIT = sd(inputTime), mPT = mean(prepTime), sdPT = sd(prepTime), mET = mean(entryTime), sdET=sd(entryTime), mTT = mean(totalTime), sdTT = sd(totalTime), meanWpm = mean(wpm), sdWpm = sd(wpm), mean_uer = mean(uncorrected_error_rate), sd_uer = sd(uncorrected_error_rate), mean_cer= mean(corrected_error_rate), sd_cer = sd(corrected_error_rate), mean_bd = mean(bandwidth))

cko.tt <- filter(data_c.kbd, totalTime < (dcs$mTT[1] - 3 * dcs$sdTT[1]) | totalTime > (dcs$mTT[1] + 3 * dcs$sdTT[1]))
cso.tt <- filter(data_c.sr, totalTime < (dcs$mTT[2] - 3 * dcs$sdTT[2]) | totalTime > (dcs$mTT[2] + 3 * dcs$sdTT[2]))
co.tt <- bind_rows(cko.tt, cso.tt)

data_c.clean = anti_join(data_c, co.tt)
#remove(co.all, co.it, co.pt, co.et, co.tt, co.wpm, co.uer, co.cer)
```

26 outliers identified for transcription (2.32% of trials)

```{r outlier_trans, warning=FALSE, message=FALSE, echo=FALSE}
dts = summarize(group_by(data_t, inputType), mIT = mean(inputTime), sdIT = sd(inputTime), mPT = mean(prepTime), sdPT = sd(prepTime), mET = mean(entryTime), sdET=sd(entryTime), mTT = mean(totalTime), sdTT = sd(totalTime), meanWpm = mean(wpm), sdWpm = sd(wpm), mean_uer = mean(uncorrected_error_rate), sd_uer = sd(uncorrected_error_rate), mean_cer= mean(corrected_error_rate), sd_cer = sd(corrected_error_rate), mean_bd = mean(bandwidth))

tko.tt <- filter(data_t.kbd, totalTime < (dts$mTT[1] - 3 * dts$sdTT[1]) | totalTime > (dts$mTT[1] + 3 * dts$sdTT[1]))
tso.tt <- filter(data_t.sr, totalTime < (dts$mTT[2] - 3 * dts$sdTT[2]) | totalTime > (dts$mTT[2] + 3 * dts$sdTT[2]))
to.tt <- bind_rows(tko.tt, tso.tt)
# 
# to.all <- bind_rows(to.it, to.pt, to.et, to.tt, to.wpm, to.uer, to.cer)
# to <- unique(to.all)

data_t.clean = anti_join(data_t, to.tt)
#remove(to.all, to.it, to.pt, to.et, to.tt, to.wpm, to.uer, to.cer)

```

## Data Aggregation

Aggregating the cleaned data

```{r warning=FALSE}
data = bind_rows(data_t.clean, data_c.clean)

data.group = summarize(group_by(data, participantNo, inputType, taskType, setNum), meanInputTime = mean(inputTime), meanPrepTime = mean(prepTime), meanEntryTime = mean(entryTime), meanTotalTime = mean(totalTime), meanLen = mean(msgLen), meanWpm = mean(wpm), mean_uer = mean(uncorrected_error_rate), mean_cer= mean(corrected_error_rate), mean_bd = mean(bandwidth), meanCorrTime = mean(corrTime))

data.stats = dplyr::bind_rows(data_c.clean, data_t.clean) %>% 
  group_by(inputType, taskType) %>% 
  summarize(mIT = mean(inputTime), cuIT = ci(inputTime)[3], clIT = ci(inputTime)[2], sdIT = sd(inputTime),
            mPT = mean(prepTime), cuPT = ci(prepTime)[3], clPT = ci(prepTime)[2], sdPT = sd(prepTime),
            mET = mean(entryTime), cuET=ci(entryTime)[3], clET = ci(entryTime)[2], sdET = sd(entryTime),
            mTT = mean(totalTime), cuTT = ci(totalTime)[3], clTT = ci(totalTime)[2], sdTT = sd(totalTime),
            mCT = mean(corrTime), cuCT = ci(corrTime)[3], clCT = ci(corrTime)[2], sdCT = sd(corrTime),
            mWpm = mean(wpm), cuWpm = ci(wpm)[3], clWpm = ci(wpm)[2], sdWpm = sd(wpm),
            m_uer = mean(uncorrected_error_rate), cu_uer = ci(uncorrected_error_rate)[3], cl_uer = ci(uncorrected_error_rate)[2], sd_uer = sd(uncorrected_error_rate),
            m_cer= mean(corrected_error_rate), cu_cer = ci(corrected_error_rate)[3], cl_cer = ci(corrected_error_rate)[2], sd_cer = sd(corrected_error_rate),
            m_bd = mean(bandwidth), cuBD = ci(bandwidth)[3], clBD = ci(bandwidth)[2], sdBD = sd(bandwidth)) 

stats.uer = group_by(data, inputType) %>%
  summarize(m_uer = mean(uncorrected_error_rate))

stats.cer = group_by(data, taskType) %>%
  summarize(m_cer = mean(corrected_error_rate))

data.long = melt(data.group, id = c("participantNo", "inputType", "taskType", "setNum", "meanInputTime", "meanPrepTime", "meanWpm", "meanTotalTime", "meanEntryTime", "meanLen", "mean_uer", "mean_cer", "mean_bd", "meanCorrTime"))

data.long$participantNo <- factor(data.long$participantNo)
data.long$inputType <- factor(data.long$inputType)

data.long.c = filter(data.long, taskType == "Composition")
data.long.c = data.long.c[,!names(data.long.c) %in% c("taskType")]

data.long.t = filter(data.long, taskType == "Transcription")
data.long.t = data.long.t[,!names(data.long.t) %in% c("taskType")]

data.long$setNum <- factor(data.long$setNum)
data.long$taskType <- factor(data.long$taskType)

data.long.c$setNum <- factor(data.long.c$setNum)
data.long.t$setNum <- factor(data.long.t$setNum)
```

Output data stats to a Latex table

Psych, this didn't actually work that well....
```{r}
#data.stats.i = unite(data.stats, "ti", taskType, inputType) 
#data.stats.i = data.stats.i[order(data.stats.i$ti),]

#data.tbl <- dplyr::select(data.stats.i, ti, mTT, sdTT, mIT, sdIT, mPT, sdPT, mET, sdET, mWpm, sdWpm, m_uer, sd_uer, m_cer, sd_cer) %>% t %>% as.data.frame()

#print(xtable(data.tbl, type = "latex"), file = "autogen/table.tex")
```

# Input Time

## Chart
```{r}
kable(dplyr::select(data.stats, inputType, taskType, mIT, sdIT))
```

## Bar Graph

```{r itgraph, warning=FALSE, message=FALSE}
createPlot(data.stats, "mIT", "clIT", "cuIT", 3.5, 0.9, 0.85, "Average Input Time (s)")
ggsave("autogen/inputtime.pdf")
```

##Effects of SetNum

```{r}
boxcox(meanInputTime ~ inputType*setNum, data=data.long.c, plotit=T)
boxcox(meanInputTime ~ inputType*setNum, data=data.long.t, plotit=T)

datatr.c = data.long.c %>% mutate(meanInputTime = log(meanInputTime))
datatr.t = data.long.t %>% mutate(meanInputTime = log(meanInputTime))

m <- aov(meanInputTime ~ inputType*setNum, data=datatr.c)
pander(normalCheck(m))

m <- aov(meanInputTime ~ setNum*inputType, data=datatr.t)
pander(normalCheck(m))
```


Data is now normally distributed.

```{r , warning=FALSE}
anova = ezANOVA(datatr.c, dv=.(meanInputTime), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))

anova = ezANOVA(datatr.t, dv=.(meanInputTime), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))
```

No significant effect of setNum.

## Effects of Input Type and Task Type

### Normality Check

```{r itnormal}
m <- aov(meanInputTime ~ taskType*inputType, data=data.long)
pander(normalCheck(m))
```

The data is not normally distributed.

### Box-Cox Transformation
```{r itbc}
boxcox(meanInputTime ~ inputType*taskType, data=data.long, plotit=T)
```

An effective lambda value is 0.0 (a.k.a, a log transformation).

```{r ittransform}
datatr = data.long %>%
    mutate(meanInputTime = log(meanInputTime))

m <- aov(meanInputTime ~ taskType*inputType, data=datatr)
pander(normalCheck(m))
```

### Repeated measures ANOVA on transformed data

```{r itanova, warning=FALSE}
anova = ezANOVA(datatr, dv=.(meanInputTime), wid=.(participantNo), within=.(inputType,taskType), detailed=TRUE)
# kable(anova$`Mauchly's Test for Sphericity`)
# kable(anova$`Sphericity Corrections`)
# kable(anova$ANOVA)
anova_apa = anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE)
input = anova_apa$text[2]
task = anova_apa$text[3]
kable(anova_apa)
```

There are significant differences between input type and task type, but not the interaction between the two.

### Post-hoc analysis with Bonferroni correction

```{r itph}
# attach(datatr)
# pw <- pairwise.t.test(meanInputTime, interaction(inputType, taskType), p.adj = "bonferroni")
# detach(datatr)
# kable(pw$p.value)
```

```{python}
s = "There were significant differences between \\f{speech} and \\f{keyboard}, and between \\f{composition} and \\f{transcription} on Box-Cox transformed \\m{Input Time} (%s) (%s)." % (parseAnova(r.input), parseAnova(r.task))
writeToFile(s, "inputtime.tex")
```

# Prep Time

## Chart
```{r}
kable(dplyr::select(data.stats, inputType, taskType, mPT, sdPT))
```

## Bar Graph

```{r ptgraph, warning=FALSE, message=FALSE}
# ggplot(data.stats, aes(x=taskType, y=mPT, color=inputType)) + 
#   geom_line(aes(group=inputType), size=0.9) +
#   geom_point() +
#   geom_errorbar(aes(ymin = clPT, ymax = cuPT), width = 0.1, size = 0.7) +
#   scale_x_discrete(name="Task") +
#   scale_y_continuous(name="Average Prep Time (ms)") 
createPlot(data.stats, "mPT", "clPT", "cuPT", 3, 0.9, 0.85, "Average Input Time (s)")
```

##Effects of SetNum

```{r}
boxcox(meanPrepTime ~ inputType*setNum, data=data.long.c, plotit=T)
boxcox(meanPrepTime ~ inputType*setNum, data=data.long.t, plotit=T)

datatr.c = data.long.c %>% mutate(meanPrepTime = meanPrepTime^(0.1))
datatr.t = data.long.t %>% mutate(meanPrepTime = meanPrepTime^(0.1))

m <- aov(meanPrepTime ~ inputType*setNum, data=datatr.c)
pander(normalCheck(m))

m <- aov(meanPrepTime ~ setNum*inputType, data=datatr.t)
pander(normalCheck(m))
```

```{r , warning=FALSE}
anova = ezANOVA(datatr.c, dv=.(meanPrepTime), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))

anova = ezANOVA(datatr.t, dv=.(meanPrepTime), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))
```

No significant effect of setNum on prep time.

## Effects of Input Type and Task Type 

### Normality Check

```{r ptnormal}
m <- aov(meanPrepTime ~ taskType*inputType, data=data.long)
pander(normalCheck(m))
```

The data is not normally distributed.

### Box-Cox Transformation

```{r ptbc}
boxcox(meanPrepTime ~ inputType*taskType, data=data.long, plotit=T)
```

An effective lambda value is -0.1.

```{r pttransform}
datatr = data.long %>%
    mutate(meanPrepTime = meanPrepTime^(-0.1))

m <- aov(meanPrepTime ~ taskType*inputType, data=datatr)
pander(normalCheck(m))

```

### Repeated measures ANOVA on transformed data

```{r ptanova, warning=FALSE}
anova = ezANOVA(datatr, dv=.(meanPrepTime), wid=.(participantNo), within=.(inputType,taskType), detailed=TRUE)

# kable(anova$`Mauchly's Test for Sphericity`)
# kable(anova$`Sphericity Corrections`)
# kable(anova$ANOVA)
anova_apa = anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE)
input = anova_apa$text[2]
task = anova_apa$text[3]
inter = anova_apa$text[4]
kable(anova_apa)
```

There are significant differences between input type and task type (both p < 0.01), and for the interaction between the two (p < 0.05).

### Post-hoc analysis with Tukey HSD

```{r ptph}
t <- TukeyHSD(m)
kable(t$`taskType:inputType`)
```

Everything but the Transcription:Speech vs. Composition:Keyboard comparison is significant.

```{python}
s = "There were significant differences between \\f{speech} and \\f{keyboard} (%s), and between \\f{composition} and \\f{transcription} on Box-Cox transformed \\m{Prep Time} (%s). There was also a significant interaction between \\f{Method} and \\f{Task} (%s)" % (parseAnova(r.input), parseAnova(r.task), parseAnova(r.inter))
writeToFile(s, "preptime.tex")
```

# Total Time

## Chart
```{r}
kable(dplyr::select(data.stats, inputType, taskType, mTT, sdTT))
```

## Bar Graph

```{r ttgraph, warning=FALSE, message=FALSE}
# ggplot(data.stats, aes(x=taskType, y=mTT, color=inputType)) + 
#   geom_line(aes(group=inputType), size=0.9) +
#   geom_point() +
#   geom_errorbar(aes(ymin = clTT, ymax = cuTT), width = 0.1, size = 0.7) +
#   scale_x_discrete(name="Task") +
#   scale_y_continuous(name="Average Total Time (ms)") 
createPlot(data.stats, "mTT", "clTT", "cuTT", 2.5, 0.9, 0.85, "Average Total Time (s)")
```

## Effects of SetNum

```{r}
boxcox(meanTotalTime ~ inputType*setNum, data=data.long.c, plotit=T)
boxcox(meanTotalTime ~ inputType*setNum, data=data.long.t, plotit=T)

datatr.c = data.long.c %>% mutate(meanTotalTime = log(meanTotalTime))
datatr.t = data.long.t %>% mutate(meanTotalTime = meanTotalTime^(-0.5))

m <- aov(meanTotalTime ~ inputType*setNum, data=datatr.c)
pander(normalCheck(m))

m <- aov(meanTotalTime ~ setNum*inputType, data=datatr.t)
pander(normalCheck(m))
```

```{r , warning=FALSE}
anova = ezANOVA(datatr.c, dv=.(meanTotalTime), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))

anova = ezANOVA(datatr.t, dv=.(meanTotalTime), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))
```

No significant effect of setNum on total time.

## Effects of Input Type and Task Type

### Normality Check

```{r ttnormal}
m <- aov(meanTotalTime ~ taskType*inputType, data=data.long)
pander(normalCheck(m))
```

The data is not normally distributed.

### Box-Cox Transformation
```{r ttbc}
boxcox(meanTotalTime ~ inputType*taskType, data=data.long, plotit=T)
```

An effective lambda value is -0.25.

```{r tttransform}
datatr = data.long %>%
    mutate(meanTotalTime = meanTotalTime^(-0.25))

m <- aov(meanTotalTime ~ taskType*inputType, data=datatr)
pander(normalCheck(m))

```

### Repeated measures ANOVA on transformed data
```{r ttanova, warning=FALSE}
anova = ezANOVA(datatr, dv=.(meanTotalTime), wid=.(participantNo), within=.(inputType,taskType), detailed=TRUE)

# kable(anova$`Mauchly's Test for Sphericity`)
# kable(anova$`Sphericity Corrections`)
# kable(anova$ANOVA)
anova_apa = anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE)
input = anova_apa$text[2]
task = anova_apa$text[3]
inter = anova_apa$text[4]
kable(anova_apa)
```

Everything is significant.

### Post-hoc analysis with Tukey HSD

```{r ttph}
t <- TukeyHSD(m)
kable(t$`taskType:inputType`)
```

```{python}
s = "There is a significant main effect of \\f{Input} (%s), and \\f{Task} on Box-Cox transformed \\m{Total Time} (%s). There was also a significant interaction between \\f{Input} and \\f{Task} (%s)" % (parseAnova(r.input), parseAnova(r.task), parseAnova(r.inter))
writeToFile(s, "totaltime.tex")
```

# Correction Time

## Chart
```{r}
kable(dplyr::select(data.stats, inputType, taskType, mCT, sdCT))
```

## Bar Graph

```{r ctgraph, warning=FALSE, message=FALSE}
createPlot(data.stats, "mCT", "clCT", "cuCT", 2.5, .9, .85, "Average Correction Time (s)", lim_min = 0, lim_max = 17)
ggsave("autogen/corrtime.pdf")
```

## Effects of SetNum

```{r}
boxcox(meanCorrTime ~ inputType*setNum, data=data.long.c, plotit=T)
boxcox(meanCorrTime ~ inputType*setNum, data=data.long.t, plotit=T)

datatr.c = data.long.c %>% mutate(meanCorrTime = log(meanCorrTime))
datatr.t = data.long.t %>% mutate(meanCorrTime = meanCorrTime^(0.2))

m <- aov(meanCorrTime ~ inputType*setNum, data=datatr.c)
pander(normalCheck(m))

m <- aov(meanCorrTime ~ setNum*inputType, data=datatr.t)
pander(normalCheck(m))
```


Data is now normally distributed.

```{r , warning=FALSE}
anova = ezANOVA(datatr.c, dv=.(meanCorrTime), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))

anova = ezANOVA(datatr.t, dv=.(meanCorrTime), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))
```

No significant effect of setNum on corrTime.

## Effects of Input Type and Task Type

### Normality Check

```{r ctnormal}
m <- aov(meanCorrTime ~ taskType*inputType, data=data.long)
pander(normalCheck(m))
```

The data is not normally distributed.

### Box-Cox Transformation
```{r ctbc}
boxcox(meanCorrTime ~ inputType*taskType, data=data.long, plotit=T)
```

An effective lambda value is 0.1.

```{r cttransform}
datatr = data.long %>%
    mutate(meanCorrTime = meanCorrTime^(0.1))

m <- aov(meanCorrTime ~ taskType*inputType, data=datatr)
pander(normalCheck(m))
```

### Repeated measures ANOVA on transformed data

```{r ctanova, warning=FALSE}
anova = ezANOVA(datatr, dv=.(meanCorrTime), wid=.(participantNo), within=.(inputType,taskType), detailed=TRUE)
# kable(anova$`Mauchly's Test for Sphericity`)
# kable(anova$`Sphericity Corrections`)
# kable(anova$ANOVA)
anova_apa = anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE)
input = anova_apa$text[2]
task = anova_apa$text[3]
kable(anova_apa)
```

There are significant differences between input type and task type, but not the interaction between the two.

# Words per Minute

## Chart
```{r}
kable(dplyr::select(data.stats, inputType, taskType, mWpm, sdWpm))
```

## Bar Graph

```{r wpmgraph, warning=FALSE, message=FALSE}
createPlot(data.stats, "mWpm", "clWpm", "cuWpm", 3, .15, .85, "Average WPM", 0, 180, 50)
```

## Effects of SetNum

```{r}
boxcox(meanWpm ~ inputType*setNum, data=data.long.c, plotit=T)
boxcox(meanWpm ~ inputType*setNum, data=data.long.t, plotit=T)

datatr.c = data.long.c %>% mutate(meanWpm = log(meanWpm))
datatr.t = data.long.t %>% mutate(meanWpm = meanWpm^(0.28))

m <- aov(meanWpm ~ inputType*setNum, data=datatr.c)
pander(normalCheck(m))

m <- aov(meanWpm ~ setNum*inputType, data=datatr.t)
pander(normalCheck(m))
```

```{r , warning=FALSE}
anova = ezANOVA(datatr.c, dv=.(meanWpm), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))

anova = ezANOVA(datatr.t, dv=.(meanWpm), wid=.(participantNo), within=.(setNum), detailed=TRUE)
kable(anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE))
```

No significant effect of setNum on WPM.

## Effects of Input Type and Task Type

### Normality Check

```{r wpmnormal}
m <- aov(meanWpm ~ taskType*inputType, data=data.long)
pander(normalCheck(m))
```

The data is not normally distributed.

### Box-Cox Transformation

```{r wpmbc}
boxcox(meanWpm ~ inputType*taskType, data=data.long, plotit=T)
```

An effective lambda value is 0.2

```{r wpmtransform}
datatr = data.long %>%
    mutate(meanWpm = meanWpm^(0.2))

m <- aov(meanWpm ~ taskType*inputType, data=datatr)
pander(normalCheck(m))
```

### Repeated measures ANOVA on transformed data

```{r wpmanova, warning=FALSE}
anova = ezANOVA(datatr, dv=.(meanWpm), wid=.(participantNo), within=.(inputType,taskType), detailed=TRUE)

anova_apa = anova_apa(anova, sph_corr ="gg", es = "ges", print=FALSE)
input = anova_apa$text[2]
task = anova_apa$text[3]
inter = anova_apa$text[4]
kable(anova_apa)
```


There are significant differences between Keyboard and Speech, and Composition and Transcription, but not the interaction between the two.

```{python}
s = "There were significant differences between \\f{speech} and \\f{keyboard} (%s), and between \\f{composition} and \\f{transcription} on Box-Cox transformed \\m{WPM} (%s)." % (parseAnova(r.input), parseAnova(r.task))
writeToFile(s, "wpm.tex")
```

# Corrected Error Rate

## Chart
```{r}
kable(dplyr::select(data.stats, inputType, taskType, m_cer, sd_cer))
```

## Bar Graph
```{r cergraph, warning=FALSE, message=FALSE}
createPlot(data.stats, "m_cer", "cl_cer", "cu_cer", 5, 0.9, 0.85, "Average Corrected Error Rate (%)", 0, 27, 5)
```


## Effects of SetNum

```{r}
a = art(mean_cer ~ setNum + (1|participantNo), data=data.long.c)
anova(a)

a = art(mean_cer ~ setNum + (1|participantNo), data=data.long.t)
anova(a)
```

No significant effect of setNum on CER

## Effects of Input Type and Task Type

### Normality Check
```{r}
m <- aov(mean_cer ~ taskType*inputType, data=data.long)
pander(normalCheck(m))
```

The data is not normally distributed. 

### ANOVAs in ART Data
```{r}
a = art(mean_cer ~ taskType*inputType + (1|participantNo), data=data.long)
anova(a)
```

Nothing significant here.

# Uncorrected Error Rate

## Chart
```{r}
kable(dplyr::select(data.stats, inputType, taskType, m_uer, sd_cer))
```

## Bar Graph
```{r uergraph, warning=FALSE, message=FALSE}
createPlot(data.stats, "m_uer", "cl_uer", "cu_uer", 5, 0.9, 0.85, "Average Uncorrected Error Rate (%)", 0, 1.5, 0.3)
```

## Effects of SetNum

```{r}
a = art(mean_uer ~ setNum + (1|participantNo), data=data.long.c)
anova(a)

a = art(mean_uer ~ setNum + (1|participantNo), data=data.long.t)
anova(a)
```

No significant effect of setNum on UER

## Effects of Input Type and Task Type

### Normality Check
```{r}
m <- aov(mean_uer ~ taskType*inputType, data=data.long)
pander(normalCheck(m))
```

The data is not normally distributed. 

### ANOVAs on ART Data

```{r}
a = art(mean_uer ~ taskType*inputType + (1|participantNo), data=data.long)
anova(a)
```

Significant effect of inputType.

# Bandwidth

## Chart
```{r}
kable(dplyr::select(data.stats, inputType, taskType, m_bd, sdBD))
```

## Bar Graph

```{r bdgraph, warning=FALSE, message=FALSE}
createPlot(data.stats, "m_bd", "clBD", "cuBD", 3, .15, .85, "Average Bandwidth", 0, 1.1, .3)
```

## Effects of SetNum

```{r}
a = art(mean_bd ~ setNum + (1|participantNo), data=data.long.c)
anova(a)

a = art(mean_bd ~ setNum + (1|participantNo), data=data.long.t)
anova(a)
```

No effect of setNum

## Effects of Input Type and Task Type


### Normality Check
```{r}
m <- aov(mean_bd ~ taskType*inputType, data=data.long)
pander(normalCheck(m))
```

The data is not normally distributed. 

### ANOVAs on ART Data

```{r}
a = art(mean_bd ~ taskType*inputType + (1|participantNo), data=data.long)
anova(a)
```

Significant effect of taskType, inputType, and their interaction.

### Post-hoc comparisons

Used Mann-Whitney U tests because nothing else worked :/

```{r}
kt_vs_st = wilcox.test(data.long[data.long$taskType == "Transcription" & data.long$inputType == "Keyboard",]$mean_bd, 
                       data.long[data.long$taskType == "Transcription" & data.long$inputType == "Speech",]$mean_bd)$p.value
kc_vs_sc = wilcox.test(data.long[data.long$taskType == "Composition" & data.long$inputType == "Keyboard",]$mean_bd, 
                       data.long[data.long$taskType == "Composition" & data.long$inputType == "Speech",]$mean_bd)$p.value
kc_vs_kt = wilcox.test(data.long[data.long$taskType == "Composition" & data.long$inputType == "Keyboard",]$mean_bd, 
                       data.long[data.long$taskType == "Transcription" & data.long$inputType == "Keyboard",]$mean_bd)$p.value
sc_vs_st = wilcox.test(data.long[data.long$taskType == "Composition" & data.long$inputType == "Speech",]$mean_bd, 
                       data.long[data.long$taskType == "Transcription" & data.long$inputType == "Speech",]$mean_bd)$p.value
kt_vs_st
kc_vs_sc
kc_vs_kt
sc_vs_st
```

Keyboard:Composition vs Speech:Compostion and Keyboard:Composition vs Keyboard:Transcription are significant.

# Composition Data

14 participants preferred the keyboard, 12 preferred speech, and 1 participant had no strong preference (they gave reasons for liking/not liking either input method). A slight majority, but not as big as I was hoping for....

# Transcription Data

Subjectively, 26 participants preferred Speech to typing - a massive majority.

# Figures

Messing around with plots to get some "paper-worthy" figures

```{r warning=FALSE, message=FALSE, include=FALSE, eval=FALSE}
tt_g <- ggplot(data.stats, aes(x=taskType, y=mTT/1000, fill=inputType)) + 
  geom_bar(aes(group=inputType), position = position_dodge(.7), colour="black", stat="identity", width=.7) + 
  geom_errorbar(aes(ymin = clTT/1000, ymax = cuTT/1000), width = 0.2, size = .5, position = position_dodge(.7)) +
  geom_text(aes(label=round(mTT/1000,digits=2)), size = 4, position = position_dodge(0.7), vjust = 2.5, alignment="center") +
  scale_x_discrete(name="Task") +
  scale_y_continuous(name="Time (s)", limits = c(0, 37), minor_breaks = 5, expand = c(0, 0)) +
  scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
  labs(fill = "Input") +
  theme(legend.position = c(.8, .8),
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        axis.text = element_text(family="Helvetica", colour="black", size="14"),
        panel.grid.major.y = element_line( size = .1, color = "grey"),
        legend.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        legend.text = element_text(family="Helvetica", face="bold", colour="black", size="14"))

it_g <-ggplot(data.stats, aes(x=taskType, y=mIT/1000, fill=inputType)) + 
  geom_bar(aes(group=inputType), position = position_dodge(.7), colour="black", stat="identity", width=.7) + 
  geom_errorbar(aes(ymin = clIT/1000, ymax = cuIT/1000), width = 0.2, size = .7, position = position_dodge(.7)) +
  geom_text(aes(label=round(mIT/1000,digits=2)), size = 4, position = position_dodge(0.7), vjust = 3.5, alignment="center") +
  scale_x_discrete(name="Task") +
  scale_y_continuous(name="Time (s)", limits = c(0, 37), minor_breaks = 5, expand = c(0, 0)) +
  #scale_fill_viridis(option="inferno", begin=0.5, end = .8, discrete = TRUE) +
  scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
  labs(fill = "Input") +  
  theme(legend.position = "none",
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        axis.text = element_text(family="Helvetica", colour="black", size="14"),
        panel.grid.major.y = element_line( size = .1, color = "grey"),
        legend.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        legend.text = element_text(family="Helvetica", face="bold", colour="black", size="14"))

pt_g <- ggplot(data.stats, aes(x=taskType, y=mPT/1000, fill=inputType)) + 
  geom_bar(aes(group=inputType), position = position_dodge(.7), colour="black", stat="identity", width=.7) + 
  geom_errorbar(aes(ymin = clPT/1000, ymax = cuPT/1000), width = 0.2, size = .5, position = position_dodge(.7)) +
  geom_text(aes(label=round(mPT/1000,digits=2)), size = 4, position = position_dodge(0.7), vjust = -2, alignment="center") +
  scale_x_discrete(name="Task") +
  scale_y_continuous(name="Time (s)", limits = c(0, 37), minor_breaks = 5, expand = c(0, 0)) +
  scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
  labs(fill = "Input") +
  theme(legend.position = "none",
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        axis.text = element_text(family="Helvetica", colour="black", size="14"),
        panel.grid.major.y = element_line( size = .1, color = "grey"),
        legend.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        legend.text = element_text(family="Helvetica", face="bold", colour="black", size="14"))

wpm_g <- ggplot(data.stats, aes(x=taskType, y=mWpm, fill=inputType)) + 
  geom_bar(aes(group=inputType), position = position_dodge(.7), colour="black", stat="identity", width=.7) + 
  geom_errorbar(aes(ymin = clWpm, ymax = cuWpm), width = 0.2, size = .5, position = position_dodge(.7)) +
  geom_text(aes(label=round(mWpm,digits=2)), size = 3, position = position_dodge(0.7), vjust = 2.5, alignment="center") +
  scale_x_discrete(name="Task") +
  scale_y_continuous(name="Average WPM", limits = c(0, 210), minor_breaks = 50, expand = c(0, 0)) +
  scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
  labs(fill = "Input") +
  theme(legend.position = c(.25,.82),
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="10"),
        axis.text = element_text(family="Helvetica", colour="black", size="10"),
        panel.grid.major.y = element_line( size = .1, color = "grey"),
        legend.title = element_text(family="Helvetica", face="bold", colour="black", size="8"),
        legend.text = element_text(family="Helvetica", face="bold", colour="black", size="8")) 

cer_g <- ggplot(data.stats, aes(x=taskType, y=m_cer*100, fill=inputType)) + 
  geom_bar(aes(group=inputType), position = position_dodge(.7), colour="black", stat="identity", width=.7) + 
  geom_errorbar(aes(ymin = cl_cer * 100, ymax = cu_cer *100), width = 0.2, size = .5, position = position_dodge(.7)) +
  geom_text(aes(label=round(m_cer * 100,digits=2)), size = 4, position = position_dodge(0.7), vjust = 5, alignment="center") +
  expand_limits(y = c(0,25)) +
  scale_x_discrete(name="Task") +
  scale_y_continuous(name="Error Rate (%)", limits = c(0, 27), minor_breaks = 5, expand = c(0, 0)) +
  scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
  labs(fill = "Input") +
  theme(legend.position = "none",
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        axis.text = element_text(family="Helvetica", colour="black", size="14"),
        panel.grid.major.y = element_line( size = .1, color = "grey"),
        legend.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        legend.text = element_text(family="Helvetica", face="bold", colour="black", size="14"))

uer_g <- ggplot(data.stats, aes(x=taskType, y=m_uer*100, fill=inputType)) + 
  geom_bar(aes(group=inputType), position = position_dodge(.7), colour="black", stat="identity", width=.7) + 
  geom_errorbar(aes(ymin = cl_uer*100, ymax = cu_uer*100), width = 0.2, size = .5, position = position_dodge(.7)) +
  geom_text(aes(label=round(m_uer * 100,digits=2)), size = 4, position = position_dodge(0.7), vjust = 4, alignment="center") +
  scale_x_discrete(name="Task") +
  scale_y_continuous(name="Error Rate (%)", limits = c(0, 2.2), minor_breaks = .3, expand = c(0, 0)) +
  scale_fill_manual(values=c("#DF5E28", "#F6C584")) +
  labs(fill = "Input") +
  theme(legend.position = c(.3, .85),
        legend.box.background = element_rect(size=1, color="black"),
        legend.background = element_rect(size = 0.3, linetype = "solid", colour = "black"),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        axis.text = element_text(family="Helvetica", colour="black", size="14"),
        panel.grid.major.y = element_line( size = .1, color = "grey"),
        legend.title = element_text(family="Helvetica", face="bold", colour="black", size="14"),
        legend.text = element_text(family="Helvetica", face="bold", colour="black", size="14"))
```

```{r warning=FALSE, message=FALSE, include=FALSE, eval=FALSE}
ggarrange(tt_g, pt_g, it_g,
          nrow = 1, ncol = 3,
          labels = c("(a) Total Time", "(b) Prep Time", "(c) Input Time"),
          font.label = list(size = 14, family="Helvetica"),
          common.legend = TRUE, legend="bottom")

ggsave("figures/speed.pdf",
       height = 4 , width = 14,
       plot = last_plot(), # or give ggplot object name as in myPlot,
       dpi = 300)
# 
# ggsave("figures/wpm.pdf",
#         height = 2.5 , width = 3.5,
#         plot = wpm_g, # or give ggplot object name as in myPlot,
#         dpi = 300)

ggarrange(uer_g, cer_g,
          nrow = 1, ncol = 2,
          labels = c("(a) Uncorrected", "(b) Corrected"),
          font.label = list(size = 14, family="Helvetica"),
          common.legend = TRUE, legend="bottom")

ggsave("figures/error.pdf",
       height = 4 , width = 7,
       plot = last_plot(), # or give ggplot object name as in myPlot,
       dpi = 300)

# ggsave("figures/error_pos.pdf",
#        height = 7 , width = 14,
#        plot = last_plot(), # or give ggplot object name as in myPlot,
#        dpi = 300)

# ggarrange(pt_g, it_g,
#           nrow = 1, ncol = 2,
#           common.legend = TRUE, legend="bottom")
# 
# ggsave("figures/speed_pos.pdf",
#        height = 7 , width = 14,
#        plot = last_plot(), # or give ggplot object name as in myPlot,
#        dpi = 300)
```


